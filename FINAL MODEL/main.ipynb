{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code snippet is a Python script for real-time multi-object tracking using YOLOv5 for object detection and a Simple Online and Realtime Tracking (SORT) algorithm for tracking. Here's a breakdown of what the code does:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python\n",
    "#%pip install torch\n",
    "#%pip install pandas\n",
    "#%pip install requests\n",
    "#%pip install Pillow\n",
    "#%pip install filterpy\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from filterpy.kalman import KalmanFilter\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "# Load the YOLOv5 model (YOLOv5m is used for better accuracy)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m')\n",
    "\n",
    "# COCO class labels with custom names\n",
    "class_labels = {\n",
    "    2: 'Car',\n",
    "    3: 'Motorbike',\n",
    "    5: 'Bus',\n",
    "    7: 'Truck',\n",
    "    0: 'Person',\n",
    "    1: 'Bicycle',\n",
    "    9: 'Three-wheeler',  # Placeholder for custom class (if available)\n",
    "}\n",
    "\n",
    "# Dictionary to track object appearance times and first seen timestamps\n",
    "track_times = {}\n",
    "active_tracks = {}\n",
    "\n",
    "# Capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to log data to a text file\n",
    "def log_to_file(object_id, label, duration, first_seen, last_seen):\n",
    "    with open(\"tracking_log.txt\", \"a\") as file:\n",
    "        file.write(f\"ID: {object_id}, Type: {label}, Duration: {duration:.2f} seconds, First seen: {first_seen}, Last seen: {last_seen}\\n\")\n",
    "\n",
    "# SORT Tracker Class (Simple implementation for tracking)\n",
    "class SORT:\n",
    "    def __init__(self):\n",
    "        self.trackers = []\n",
    "        self.next_id = 0\n",
    "\n",
    "    def update(self, detections):\n",
    "        updated_tracks = []\n",
    "        for det in detections:\n",
    "            tracker = KalmanFilter(dim_x=7, dim_z=4)\n",
    "            tracker.x[:4] = np.array([det[0], det[1], det[2], det[3]]).reshape((4, 1))\n",
    "            tracker.F = np.eye(7)\n",
    "            tracker.H = np.eye(4, 7)\n",
    "            tracker.P *= 10.\n",
    "            tracker.id = self.next_id\n",
    "            self.next_id += 1\n",
    "            updated_tracks.append(tracker)\n",
    "        return updated_tracks\n",
    "\n",
    "# Initialize SORT tracker\n",
    "tracker = SORT()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally to correct axis\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Object detection using YOLOv5\n",
    "    results = model(frame)\n",
    "    detections = results.xyxy[0].cpu().numpy()  # Bounding boxes (x1, y1, x2, y2, confidence, class)\n",
    "\n",
    "    # Filter vehicle and person detections\n",
    "    vehicle_classes = [2, 3, 5, 7, 1, 9]  # Car, Motorbike, Bus, Truck, Bicycle, Three-wheeler\n",
    "    vehicles = [d for d in detections if int(d[5]) in vehicle_classes and d[4] > 0.4]\n",
    "    people = [d for d in detections if int(d[5]) == 0 and d[4] > 0.4]  # Detect people (class 0)\n",
    "\n",
    "    # Combine vehicles and people detections\n",
    "    detections = vehicles + people\n",
    "\n",
    "    # Track current frame's object IDs\n",
    "    current_frame_ids = set()\n",
    "\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2, conf, cls = det\n",
    "        label = class_labels.get(int(cls), 'Unknown')\n",
    "        object_id = int(x1) + int(y1)  # Simple way to generate ID (replace with better tracking logic)\n",
    "\n",
    "        current_frame_ids.add(object_id)\n",
    "\n",
    "        # If the object is new, record the appearance time\n",
    "        if object_id not in active_tracks:\n",
    "            active_tracks[object_id] = {'first_seen': time.time(), 'label': label}\n",
    "\n",
    "        # Draw bounding box in green\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display ID and label in red\n",
    "        cv2.putText(frame, f'{label} ID: {object_id}', (int(x1), int(y1) - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Check for objects that have left the frame\n",
    "    for object_id in list(active_tracks.keys()):\n",
    "        if object_id not in current_frame_ids:\n",
    "            first_seen = active_tracks[object_id]['first_seen']\n",
    "            last_seen = time.time()\n",
    "            duration = last_seen - first_seen\n",
    "            log_to_file(object_id, active_tracks[object_id]['label'], duration, first_seen, last_seen)  # Log data to file\n",
    "            del active_tracks[object_id]  # Remove the object from active tracks\n",
    "\n",
    "    # Display the frame with tracking\n",
    "    cv2.imshow('Real-Time Multi-Object Tracking', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we included a phase where it records the objects log With the GUI and made it more accruate by yolov5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# tkinter: For creating the GUI\n",
    "# ttk: For creating styled widgets in Tkinter\n",
    "# PIL: For handling images and converting between formats in Tkinter\n",
    "# cv2: For capturing video and performing computer vision tasks\n",
    "# threading: For running the video processing in a separate thread to keep the GUI responsive\n",
    "# torch: For using the YOLOv5 model for object detection\n",
    "# time: For tracking object detection times and managing state\n",
    "\n",
    "# Load the YOLOv5 model (medium version) for object detection\n",
    "\n",
    "# Dictionary mapping COCO class IDs to labels (specifically customized for vehicles and people)\n",
    "\n",
    "# Class definition for TrackingApp: \n",
    "# Initializes the GUI, video capture, and manages the real-time tracking of objects using YOLOv5\n",
    "# Contains methods for starting and stopping the tracking process, logging data, and processing video frames\n",
    "# Displays detected objects, labels, and their respective bounding boxes on the live video feed\n",
    "# Uses threading to process the video in the background without blocking the GUI\n",
    "\n",
    "# Start and stop tracking buttons to begin and end the object detection process\n",
    "# The log text area shows the logs of detected objects and their IDs in real-time\n",
    "\n",
    "# video processing function:\n",
    "# Captures each frame from the webcam, processes it for object detection, and displays the results\n",
    "# Uses the YOLOv5 model to detect objects in the video frame\n",
    "# Each detected object is assigned an ID and logged in the GUI\n",
    "# Detected objects are highlighted with bounding boxes and labels\n",
    "# Updates the displayed video feed in the GUI with each processed frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m')\n",
    "\n",
    "# Dictionary for COCO class labels (customized for vehicles and people)\n",
    "class_labels = {\n",
    "    0: 'Person',\n",
    "    2: 'Car',\n",
    "    3: 'Motorbike',\n",
    "    5: 'Bus',\n",
    "    7: 'Truck',\n",
    "    1: 'Bicycle',\n",
    "    9: 'Three-wheeler',  # Custom class (if defined)\n",
    "}\n",
    "\n",
    "class TrackingApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Real-Time Multi-Object Tracking\")\n",
    "        self.root.geometry(\"900x700\")\n",
    "        self.cap = cv2.VideoCapture(0)  # Initialize webcam\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Create GUI components\n",
    "        self.video_frame = ttk.Label(root)\n",
    "        self.video_frame.pack(pady=20)\n",
    "        \n",
    "        self.start_button = ttk.Button(root, text=\"Start Tracking\", command=self.start_tracking)\n",
    "        self.start_button.pack(side=tk.LEFT, padx=20)\n",
    "        \n",
    "        self.stop_button = ttk.Button(root, text=\"Stop Tracking\", command=self.stop_tracking)\n",
    "        self.stop_button.pack(side=tk.RIGHT, padx=20)\n",
    "        \n",
    "        # Display area for logs\n",
    "        self.log_text = tk.Text(root, height=10, width=100)\n",
    "        self.log_text.pack(pady=10)\n",
    "        \n",
    "        self.active_tracks = {}\n",
    "\n",
    "    def start_tracking(self):\n",
    "        if not self.is_running:\n",
    "            self.is_running = True\n",
    "            self.thread = threading.Thread(target=self.process_video)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop_tracking(self):\n",
    "        self.is_running = False\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def log_data(self, message):\n",
    "        self.log_text.insert(tk.END, message + '\\n')\n",
    "        self.log_text.see(tk.END)\n",
    "\n",
    "    def process_video(self):\n",
    "        while self.is_running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Flip the frame horizontally\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # Object detection using YOLOv5\n",
    "            results = model(frame)\n",
    "            detections = results.xyxy[0].cpu().numpy()\n",
    "            \n",
    "            current_frame_ids = set()\n",
    "            for det in detections:\n",
    "                x1, y1, x2, y2, conf, cls = det\n",
    "                if conf > 0.4:  # Confidence threshold\n",
    "                    label = class_labels.get(int(cls), 'Unknown')\n",
    "                    object_id = int(x1 + y1)  # Simplified ID generation\n",
    "                    \n",
    "                    # Track appearance times\n",
    "                    current_frame_ids.add(object_id)\n",
    "                    if object_id not in self.active_tracks:\n",
    "                        self.active_tracks[object_id] = time.time()\n",
    "                        self.log_data(f\"Object {label} (ID {object_id}) detected.\")\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f'{label} ID: {object_id}', (int(x1), int(y1) - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            \n",
    "            # Convert OpenCV frame (BGR) to Tkinter-compatible format (RGB)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            img_tk = ImageTk.PhotoImage(image=img)\n",
    "            self.video_frame.img_tk = img_tk\n",
    "            self.video_frame.config(image=img_tk)\n",
    "            self.root.update_idletasks()\n",
    "\n",
    "# Run the GUI application\n",
    "root = tk.Tk()\n",
    "app = TrackingApp(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Multi-Object Tracking System with GUI\n",
    "Overview\n",
    "This project integrates a real-time multi-object tracking system using YOLOv5 with a Tkinter GUI. It captures live video from the webcam, performs object detection and tracking, and displays the results along with logs in a graphical interface.\n",
    "\n",
    "## Key Features\n",
    "Start and Stop Buttons: Control the tracking process.\n",
    "Live Video Display: Shows real-time video with bounding boxes around detected objects.\n",
    "Logging Section: Provides real-time logs of detected objects and their appearance times.\n",
    "Dependencies\n",
    "Ensure you have the following Python libraries installed:\n",
    "\n",
    "pip install torch torchvision opencv-python pillow tkinter\n",
    "Code Explanation\n",
    "\n",
    "## Imports and Setup\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import torch\n",
    "import time\n",
    "Tkinter: Provides GUI components.\n",
    "Pillow (PIL): Handles image conversion for display in Tkinter.\n",
    "OpenCV: Captures video from the webcam and processes frames.\n",
    "PyTorch: Loads and runs the YOLOv5 model.\n",
    "Threading: Allows video processing to run concurrently with the GUI.\n",
    "\n",
    "## Load YOLOv5 Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m')\n",
    "YOLOv5m: Medium-sized YOLOv5 model for balanced performance and speed.\n",
    "\n",
    "## GUI Class Definition\n",
    "class TrackingApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Real-Time Multi-Object Tracking\")\n",
    "        self.root.geometry(\"900x700\")\n",
    "        ...\n",
    "TrackingApp class: Defines the main GUI and functionality.\n",
    "Window Setup: Sets title and size.\n",
    "Video Source: Captures video from the default webcam.\n",
    "\n",
    "## GUI Components\n",
    "self.video_frame = ttk.Label(root)\n",
    "self.video_frame.pack(pady=20)\n",
    "\n",
    "self.start_button = ttk.Button(root, text=\"Start Tracking\", command=self.start_tracking)\n",
    "self.start_button.pack(side=tk.LEFT, padx=20)\n",
    "\n",
    "self.stop_button = ttk.Button(root, text=\"Stop Tracking\", command=self.stop_tracking)\n",
    "self.stop_button.pack(side=tk.RIGHT, padx=20)\n",
    "\n",
    "self.log_text = tk.Text(root, height=10, width=100)\n",
    "self.log_text.pack(pady=10)\n",
    "video_frame: Displays the live video feed.\n",
    "start_button and stop_button: Control the tracking process.\n",
    "log_text: Logs detected objects and their IDs.\n",
    "\n",
    "## Start and Stop Functions\n",
    "def start_tracking(self):\n",
    "    if not self.is_running:\n",
    "        self.is_running = True\n",
    "        self.thread = threading.Thread(target=self.process_video)\n",
    "        self.thread.start()\n",
    "\n",
    "def stop_tracking(self):\n",
    "    self.is_running = False\n",
    "    self.cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "start_tracking: Initiates a separate thread for video processing.\n",
    "stop_tracking: Stops the tracking process and releases resources.\n",
    "\n",
    "## Video Processing and Detection\n",
    "def process_video(self):\n",
    "    while self.is_running:\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        results = model(frame)  # Object detection using YOLOv5\n",
    "        detections = results.xyxy[0].cpu().numpy()\n",
    "        ...\n",
    "        \n",
    "        # Convert and display the frame\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        self.video_frame.img_tk = img_tk\n",
    "        self.video_frame.config(image=img_tk)\n",
    "        self.root.update_idletasks()\n",
    "Frame Capture: Reads frames from the webcam.\n",
    "Object Detection: Runs YOLOv5 on each frame and retrieves detection results.\n",
    "Frame Display: Converts the frame to RGB and displays it in the GUI.\n",
    "\n",
    "## Logging Mechanism\n",
    "def log_data(self, message):\n",
    "    self.log_text.insert(tk.END, message + '\\n')\n",
    "    self.log_text.see(tk.END)\n",
    "Logs detected objects and their IDs in the Text widget.\n",
    "Customization Options\n",
    "Class Labels: Modify the class_labels dictionary to track different object classes.\n",
    "Confidence Threshold: Adjust the conf > 0.4 threshold for detection sensitivity.\n",
    "Video Source: Change self.cap = cv2.VideoCapture(0) to use a different video source or file.\n",
    "Running the Application\n",
    "Ensure your webcam is connected.\n",
    "\n",
    "## Run the script:\n",
    "python tracking_app.py\n",
    "Use the Start and Stop buttons to control tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
